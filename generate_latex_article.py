#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# LaTeX Article Generator for Systematic Review
# Generates a publication-ready LaTeX article from systematic review data.
# Uses direct HTTP API calls to LLM for article generation.
#
# Copyright (C) 2026  Costin Stroie <costinstroie@eridu.eu.org>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# Author: Costin Stroie <costinstroie@eridu.eu.org>
# GitHub: https://github.com/cstroie/SystematicReviewAssistant
"""
LaTeX Article Generator for Systematic Review

Generates a publication-ready LaTeX article from systematic review data.
Uses direct HTTP API calls to LLM for article generation.

Features:
- Comprehensive article structure (PRISMA 2020 compliant)
- Thematic synthesis integration
- Publication-ready formatting
- Multiple output formats

Usage:
    python generate_latex_article.py workdir
    python generate_latex_article.py workdir --provider anthropic
    python generate_latex_article.py workdir --model claude-opus-4-5-20251101
"""

import json
import csv
import urllib.request
import urllib.error
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import argparse
import os
import time


class ArticleDataCollector:
    """Collects and prepares systematic review data from pipeline outputs.

    This class handles loading and organizing data generated by earlier stages
    of the literature review pipeline for use in article generation. It processes
    various output files including screening results, extracted data, quality
    assessments, and thematic synthesis to create a structured dataset for
    LaTeX article generation.

    The collector handles missing files gracefully with warnings rather than
    fatal errors, ensuring the pipeline can continue even if some intermediate
    outputs are unavailable.

    Attributes:
        workdir (str): Path to the pipeline output directory containing all
                      generated files from the systematic review pipeline
        data (dict): Dictionary containing all collected and processed data,
                    organized by category (screening, extracted, quality,
                    synthesis, statistics, etc.)
    """

    def __init__(self, workdir: str):
        """Initialize data collector with output directory

        Args:
            workdir: Path to directory containing pipeline output files
        """
        self.workdir = Path(workdir)
        self.data = {
            'original_articles': []  # Articles from initial parsing
        }

    def collect_all_data(self) -> Dict:
        """Collect and organize all data from pipeline outputs.

        This method orchestrates the complete data collection process by calling
        individual loaders for each type of pipeline output. It processes files
        in a specific order to ensure dependencies are met, calculates summary
        statistics from the extracted data, and organizes everything into a
        structured dictionary ready for article generation.

        The method handles various file formats including JSON, CSV, and text
        files, with appropriate error handling for each type.

        Returns:
            dict: A comprehensive dictionary containing all collected data,
                  organized into the following sections:
                  - workdir: Path to the working directory
                  - plan: Study plan metadata
                  - screening: Screening statistics and PRISMA counts
                  - extracted: List of extracted study data
                  - quality: List of quality assessment results
                  - synthesis: Thematic synthesis text content
                  - original_articles: Original parsed article data
                  - characteristics_table: Study characteristics data
                  - statistics: Computed summary statistics

        Note:
            Missing files will generate warnings but not fatal errors. The
            method will continue processing with available data, ensuring
            robustness against incomplete pipeline outputs.
        """

        print("Collecting data from pipeline outputs...")
        self.data['workdir'] = str(self.workdir)

        # Load the study plan
        self._load_plan()

        # Load screening results
        self._load_screening_results()

        # Load extracted data
        self._load_extracted_data()

        # Load quality assessment
        self._load_quality_assessment()

        # Load original articles for reference data
        self._load_original_articles()

        # Load thematic synthesis
        self._load_thematic_synthesis()

        # Load summary characteristics
        self._load_summary_characteristics()

        # Calculate statistics
        self._calculate_statistics()

        print("✓ Data collection complete")
        return self.data

    def _load_screening_results(self) -> None:
        """Load and process screening results from JSON file.

        This method loads screening results from the standard pipeline output
        file '02_screening_results.json' and processes them to calculate
        PRISMA 2020 compliant statistics. It handles various screening
        decisions (INCLUDE, EXCLUDE, UNCERTAIN) and computes the flow
        diagram numbers required for systematic review reporting.

        The method calculates and stores:
        - Total articles identified and screened
        - Number of articles excluded at screening stage
        - Number of articles requiring full-text assessment
        - Final inclusion numbers

        Populates:
            self.data['screening'] (dict): Dictionary containing screening statistics
                with keys:
                - total_identified: Total articles found in search
                - total_screened: Articles that underwent screening
                - included: Articles marked for inclusion
                - excluded: Articles excluded at screening
                - uncertain: Articles needing full-text review
                - excluded_total: Total excluded (excluded + uncertain)
                - full_text_assessed: Articles that went to full-text
                - full_text_excluded: Articles excluded at full-text
                - final_included: Final number of included studies

        Note:
            If the file doesn't exist or contains invalid JSON, warnings are
            printed and an empty screening dictionary is stored to allow
            the pipeline to continue.
        """
        file_path = self.workdir / "02_screening_results.json"

        if not file_path.exists():
            print(f"Warning: {file_path} not found")
            self.data['screening'] = {}
            return

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
        except json.JSONDecodeError as e:
            print(f"Error: Invalid JSON in {file_path}: {str(e)}")
            self.data['screening'] = {}
            return
        except IOError as e:
            print(f"Error: Cannot read {file_path}: {str(e)}")
            self.data['screening'] = {}
            return

        total = len(results)
        included = sum(1 for r in results if r.get('decision') == 'INCLUDE')
        excluded = sum(1 for r in results if r.get('decision') == 'EXCLUDE')
        uncertain = sum(1 for r in results if r.get('decision') == 'UNCERTAIN')

        self.data['screening'] = {
            'total_identified': total,
            'total_screened': total,
            'included': included,
            'excluded': excluded,
            'uncertain': uncertain,
            'excluded_total': excluded + uncertain,  # Uncertain go to full-text
            'full_text_assessed': included + uncertain,
            'full_text_excluded': uncertain,
            'final_included': included
        }

        print(f"  Screening: {included} included, {excluded} excluded, {uncertain} uncertain")

    def _load_extracted_data(self) -> None:
        """Load extracted study data from JSON file.

        This method loads the extracted study data from the pipeline output
        file '03_extracted_data.json'. The extracted data contains detailed
        information about each included study, including methodology,
        results, and metadata collected during the data extraction phase.

        The method filters out any studies that encountered extraction
        errors, ensuring only valid data is included in the final article.

        Populates:
            self.data['extracted'] (list): List of dictionaries containing
                extracted study data. Each dictionary represents one study
                and contains fields such as:
                - title: Study title
                - authors: List of authors
                - journal: Publication journal
                - year: Publication year
                - study_design: Study methodology type
                - imaging_modality: Imaging techniques used
                - clinical_domain: Medical specialty area
                - sample_size: Patient numbers
                - key_metrics: Performance metrics
                - And other extracted fields based on the extraction form

        Note:
            Missing files or invalid JSON will generate warnings and result
            in an empty extracted data list, allowing the pipeline to continue
            with available data.
        """
        file_path = self.workdir / "03_extracted_data.json"

        if not file_path.exists():
            print(f"Warning: {file_path} not found")
            self.data['extracted'] = []
            return

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            print(f"Error: Invalid JSON in {file_path}: {str(e)}")
            self.data['extracted'] = []
            return
        except IOError as e:
            print(f"Error: Cannot read {file_path}: {str(e)}")
            self.data['extracted'] = []
            return

        # Filter out items with errors
        self.data['extracted'] = [d for d in data if 'extraction_error' not in d]

        print(f"  Extracted: {len(self.data['extracted'])} studies")

    def _load_quality_assessment(self) -> None:
        """Load quality assessment data from JSON file.

        This method loads quality assessment results from the pipeline output
        file '04_quality_assessment.json'. The quality assessment evaluates
        each study using standardized tools (typically QUADAS-2 for diagnostic
        accuracy studies) to assess risk of bias and methodological quality.

        Studies with assessment errors are filtered out to ensure only valid
        quality assessments are included in the final article.

        Populates:
            self.data['quality'] (list): List of dictionaries containing
                quality assessment results. Each dictionary includes:
                - study_id: Identifier for the study
                - overall_bias: Overall risk of bias (Low/Moderate/High)
                - domain_specific_ratings: Ratings for individual domains
                - risk_of_bias_details: Detailed assessment notes
                - And other quality assessment metrics based on the tool used

        Note:
            Missing files or invalid JSON will generate warnings and result
            in an empty quality assessment list, allowing the pipeline to
            continue with available data.
        """
        file_path = self.workdir / "04_quality_assessment.json"

        if not file_path.exists():
            print(f"Warning: {file_path} not found")
            self.data['quality'] = []
            return

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            print(f"Error: Invalid JSON in {file_path}: {str(e)}")
            self.data['quality'] = []
            return
        except IOError as e:
            print(f"Error: Cannot read {file_path}: {str(e)}")
            self.data['quality'] = []
            return

        self.data['quality'] = [d for d in data if 'assessment_error' not in d]

        print(f"  Quality assessment: {len(self.data['quality'])} studies rated")

    def _load_thematic_synthesis(self) -> None:
        """Load thematic synthesis text from file.

        This method loads the thematic synthesis text from the pipeline output
        file '05_thematic_synthesis.txt'. The thematic synthesis represents
        the qualitative analysis of the included studies, identifying key
        themes, patterns, and insights across the literature.

        The synthesis text is used directly in the article's discussion and
        thematic synthesis sections, providing the qualitative backbone
        for the systematic review's interpretation.

        Populates:
            self.data['synthesis'] (str): String containing the complete
                thematic synthesis text. This text should be ready for
                inclusion in the LaTeX article and may include:
                - Major themes identified
                - Patterns across studies
                - Contradictory findings
                - Research gaps
                - Clinical implications

        Note:
            Missing files will generate warnings and result in empty
            synthesis text, allowing the pipeline to continue. The article
            generation will handle missing synthesis appropriately.
        """
        file_path = self.workdir / "05_thematic_synthesis.txt"

        if not file_path.exists():
            print(f"Warning: {file_path} not found")
            self.data['synthesis'] = ""
            return

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                self.data['synthesis'] = f.read()
        except IOError as e:
            print(f"Error: Cannot read {file_path}: {str(e)}")
            self.data['synthesis'] = ""
            return

        print(f"  Synthesis: {len(self.data['synthesis'])} characters")

    def _load_original_articles(self) -> None:
        """Load original parsed articles from JSON file.

        This method loads the original parsed article data from the pipeline
        output file '01_parsed_articles.json'. This data contains the raw
        parsed information from PubMed or other database searches, before
        any screening or extraction was applied.

        The original articles data is used primarily for generating BibTeX
        entries and for reference when the extracted data might be missing
        certain metadata fields.

        Populates:
            self.data['original_articles'] (list): List of dictionaries
                containing original parsed article data. Each dictionary
                includes fields such as:
                - title: Article title
                - authors: List of authors
                - journal: Journal name
                - volume, issue, pages: Publication details
                - doi: Digital Object Identifier
                - pmid: PubMed ID
                - url: Direct URL to article
                - year: Publication year
                - And other metadata extracted from the original source

        Note:
            Missing files or invalid JSON will generate warnings and result
            in an empty list, but the pipeline will continue as this data
            is primarily used for reference and BibTeX generation.
        """
        file_path = self.workdir / "01_parsed_articles.json"

        if not file_path.exists():
            print(f"Warning: {file_path} not found")
            self.data['original_articles'] = []
            return

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                self.data['original_articles'] = json.load(f)
        except json.JSONDecodeError as e:
            print(f"Error: Invalid JSON in {file_path}: {str(e)}")
            self.data['original_articles'] = []
            return
        except IOError as e:
            print(f"Error: Cannot read {file_path}: {str(e)}")
            self.data['original_articles'] = []
            return

        print(f"  Original articles: {len(self.data['original_articles'])} loaded")

    def _load_plan(self) -> None:
        """Load plan metadata.

        This method loads the study plan metadata from the pipeline output
        file '00_plan.json'. The study plan contains the original research
        protocol information, including the review title, topic, search
        strategy, inclusion/exclusion criteria, and data extraction forms.

        This metadata is crucial for generating an accurate article that
        reflects the original research protocol and justifies the methods
        section.

        Populates:
            self.data['plan'] (dict): Dictionary containing study plan
                metadata with keys such as:
                - title: Systematic review title
                - topic: Research topic description
                - search: Search strategy details
                - inclusion: Inclusion criteria
                - exclusion: Exclusion criteria
                - extract: Data extraction form structure
                - analysis: Analysis points and themes
                - And other protocol information

        Note:
            Missing files or invalid JSON will generate warnings and result
            in an empty plan dictionary. The pipeline will continue, but
            the generated article may have generic content where specific
            plan information is missing.
        """
        file_path = self.workdir / "00_plan.json"

        if not file_path.exists():
            print(f"Warning: {file_path} not found")
            self.data['plan'] = {}
            return

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                self.data['plan'] = json.load(f)
        except json.JSONDecodeError as e:
            print(f"Error: Invalid JSON in {file_path}: {str(e)}")
            self.data['plan'] = {}
            return
        except IOError as e:
            print(f"Error: Cannot read {file_path}: {str(e)}")
            self.data['plan'] = {}
            return

        print(f"  Study: {self.data['plan']['title']}")

    def _load_summary_characteristics(self) -> None:
        """Load summary characteristics CSV file.

        This method loads the summary characteristics table from the pipeline
        output file 'summary_characteristics_table.csv'. This table contains
        structured data summarizing key characteristics of all included
        studies, typically organized as a matrix with studies as rows and
        characteristics as columns.

        This data is used to generate Table 1 in the systematic review,
        which provides an overview of the included studies' features.

        Populates:
            self.data['characteristics_table'] (list): List of dictionaries
                representing the characteristics table. Each dictionary
                corresponds to a row in the CSV and contains:
                - study_id: Unique identifier for each study
                - Various characteristic fields based on the extraction form
                - Values may include categorical data, numerical values,
                  or text descriptions depending on the characteristic type

        Note:
            Missing files or invalid CSV will generate warnings and result
            in an empty characteristics table. The pipeline will continue,
            but the generated article will reference a Table 1 that may
            not be present.
        """
        file_path = self.workdir / "summary_characteristics_table.csv"

        if not file_path.exists():
            print(f"Warning: {file_path} not found")
            self.data['characteristics_table'] = []
            return

        try:
            rows = []
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    rows.append(row)

            self.data['characteristics_table'] = rows
        except csv.Error as e:
            print(f"Error: Invalid CSV in {file_path}: {str(e)}")
            self.data['characteristics_table'] = []
            return
        except IOError as e:
            print(f"Error: Cannot read {file_path}: {str(e)}")
            self.data['characteristics_table'] = []
            return

        print(f"  Characteristics table: {len(rows)} studies")

    def _calculate_statistics(self) -> None:
        """Compute summary statistics from extracted data.

        This method analyzes the extracted study data to compute various
        summary statistics that are used throughout the systematic review
        article. These statistics provide quantitative insights into the
        characteristics and distribution of the included studies.

        The method calculates statistics for multiple dimensions including
        temporal distribution, imaging modalities, clinical domains, study
        designs, sample sizes, and performance metrics. These statistics
        are used in the results section and to inform the thematic synthesis.

        Populates:
            self.data['statistics'] (dict): Dictionary containing computed
                summary statistics with the following structure:
                - total_studies: Total number of included studies
                - year_range: Range of publication years (e.g., "2014-2024")
                - modalities: Dictionary of imaging modalities and counts
                - domains: Dictionary of clinical domains and counts
                - extract_fields: Statistics for each extracted field
                - study_designs: Dictionary of study designs and counts
                - sample_sizes: Dictionary with median, range, and mean
                - performance_metrics: Statistics for sensitivity, specificity, AUC

        Note:
            If no extracted data is available, the statistics dictionary
            will be empty. The pipeline handles this gracefully in the
            article generation process.
        """
        extracted = self.data.get('extracted', [])

        if not extracted:
            self.data['statistics'] = {}
            return

        stats = {
            'total_studies': len(extracted),
            'year_range': self._get_year_range(extracted),
            'modalities': self._get_modalities(extracted),
            'domains': self._get_domains(extracted),
            'extract_fields': self._get_extract_fields(extracted),
            'study_designs': self._get_study_designs(extracted),
            'sample_sizes': self._get_sample_size_stats(extracted),
            'performance_metrics': self._get_performance_metrics(extracted),
        }

        self.data['statistics'] = stats

        print(f"  Statistics: {stats['total_studies']} studies analyzed")

    def _get_year_range(self, data: List[Dict]) -> str:
        years = [int(d.get('year', 0)) for d in data if d.get('year')]
        if not years:
            return "Unknown"
        return f"{min(years)}-{max(years)}"

    def _get_modalities(self, data: List[Dict]) -> Dict[str, int]:
        modalities = {}
        for d in data:
            mods = d.get('imaging_modality', [])
            if isinstance(mods, list):
                for m in mods:
                    modalities[m] = modalities.get(m, 0) + 1
            elif isinstance(mods, str) and mods:
                modalities[mods] = modalities.get(mods, 0) + 1
        return dict(sorted(modalities.items(), key=lambda x: x[1], reverse=True))

    def _get_domains(self, data: List[Dict]) -> Dict[str, int]:
        domains = {}
        for d in data:
            domain = d.get('clinical_domain', 'Unknown')
            if domain:
                domains[domain] = domains.get(domain, 0) + 1
        return dict(sorted(domains.items(), key=lambda x: x[1], reverse=True))

    def _get_extract_fields(self, data: List[Dict]) -> Dict[str, Dict[str, int]]:
        """Get statistics for all extract fields"""
        extract_fields = {}
        plan = self.data.get('plan', {})
        extract_config = plan.get('extract', {})

        for field in extract_config.keys():
            field_values = {}
            for d in data:
                # Handle both top-level and extract section fields
                value = d.get('extract', {}).get(field) or d.get(field, 'Unknown')
                if isinstance(value, list):
                    for v in value:
                        field_values[v] = field_values.get(v, 0) + 1
                else:
                    field_values[value] = field_values.get(value, 0) + 1
            extract_fields[field] = dict(sorted(field_values.items(), key=lambda x: x[1], reverse=True))

        return extract_fields

    def _get_study_designs(self, data: List[Dict]) -> Dict[str, int]:
        designs = {}
        for d in data:
            design = d.get('study_design', 'Unknown')
            if design:
                designs[design] = designs.get(design, 0) + 1
        return dict(sorted(designs.items(), key=lambda x: x[1], reverse=True))

    def _get_sample_size_stats(self, data: List[Dict]) -> Dict:
        sizes = []
        for d in data:
            size_dict = d.get('sample_size', {})
            if isinstance(size_dict, dict):
                n = size_dict.get('total_patients')
                if n and isinstance(n, int):
                    sizes.append(n)

        if not sizes:
            return {'median': 'N/A', 'range': 'N/A', 'mean': 'N/A'}

        sizes.sort()
        return {
            'median': sizes[len(sizes)//2],
            'range': f"{min(sizes)}-{max(sizes)}",
            'mean': round(sum(sizes) / len(sizes), 0)
        }

    def _get_performance_metrics(self, data: List[Dict]) -> Dict:
        sensitivity = []
        specificity = []
        auc = []

        for d in data:
            metrics = d.get('key_metrics', {})
            if isinstance(metrics, dict):
                sens = metrics.get('sensitivity')
                spec = metrics.get('specificity')
                a = metrics.get('auc')

                if sens and isinstance(sens, (int, float)):
                    sensitivity.append(float(sens))
                if spec and isinstance(spec, (int, float)):
                    specificity.append(float(spec))
                if a and isinstance(a, (int, float)):
                    auc.append(float(a))

        return {
            'sensitivity': self._metric_stats(sensitivity),
            'specificity': self._metric_stats(specificity),
            'auc': self._metric_stats(auc),
        }

    def _metric_stats(self, values: List[float]) -> Dict:
        if not values:
            return {'median': 'N/A', 'range': 'N/A', 'count': 0}

        values.sort()
        return {
            'median': round(values[len(values)//2], 3),
            'range': f"{round(min(values), 3)}-{round(max(values), 3)}",
            'count': len(values),
            'mean': round(sum(values) / len(values), 3)
        }

    def generate_bibtex(self) -> str:
        """Generate BibTeX entries for all included studies.

        This method creates complete BibTeX entries for all studies included
        in the systematic review. It prioritizes metadata from the original
        parsed articles when available, falling back to extracted data for
        missing fields.

        The method creates unique citation keys using a hierarchical approach:
        1. Uses PMID if available and valid
        2. Falls back to DOI if available
        3. Creates author-year-index key as final fallback

        The method handles various edge cases including missing metadata,
        special characters in fields, and different author name formats.
        All BibTeX fields are properly LaTeX-escaped for compilation compatibility.

        Returns:
            str: Complete BibTeX entries as a string, with each entry
                separated by double newlines. Each entry includes:
                - Proper @article{} entry type
                - Unique citation key
                - Title, author, journal, year
                - Volume, issue, pages if available
                - DOI, PMID, URL if available
                - Proper LaTeX escaping for special characters

        Note:
            Studies with missing or invalid metadata are skipped with
            warnings, but the method continues processing remaining studies.
            The returned string may be empty if no valid studies are found.
        """
        entries = []
        extracted = self.data.get('extracted', [])
        original_articles = {art['title']: art for art in self.data.get('original_articles', [])}

        for i, study in enumerate(extracted):
            try:
                # Get original article details for more complete metadata
                original = original_articles.get(study.get('title'), {})

                # Merge fields preferring original parse data when available
                authors = original.get('authors', study.get('authors', 'Unknown'))
                journal = original.get('journal', study.get('journal', 'Unknown Journal'))
                volume = original.get('volume', study.get('volume', ''))
                issue = original.get('issue', study.get('issue', ''))
                pages = original.get('pages', study.get('pages', ''))
                doi = original.get('doi', study.get('doi', ''))
                pmid = original.get('pmid', study.get('pmid', ''))
                url = original.get('url', study.get('url', ''))
                year = original.get('year', study.get('year', '0000'))

                # Create unique citation key - prioritize PMID
                citation_key = ""
                if pmid and pmid.strip() and pmid != 'N/A':
                    citation_key = f"pmid{pmid.strip()}"
                elif doi and doi.strip() and doi != 'N/A':
                    citation_key = doi.strip()
                else:
                    # Fallback to author-year-index if no PMID/DOI
                    if isinstance(authors, list):
                        first_author_last = authors[0].split()[-1] if authors else 'Unknown'
                    else:
                        first_author_last = authors.split()[0] if authors else 'Unknown'
                    citation_key = f"{first_author_last}{year}{i:02d}".lower()

                # Format authors for BibTeX
                if isinstance(authors, list):
                    formatted_authors = " and ".join(authors)
                else:
                    formatted_authors = authors

                # LaTeX escaping for BibTeX fields (except DOI/PMID/URL which shouldn't need it)
                title = study.get('title', 'Untitled').replace('&', r'\\&').replace('$', r'\\$').replace('%', r'\\%').replace('#', r'\\#')
                journal_esc = journal.replace('&', r'\\&').replace('$', r'\\$').replace('%', r'\\%').replace('#', r'\\#')
                formatted_authors_esc = formatted_authors.replace('&', r'\\&').replace('$', r'\\$').replace('%', r'\\%').replace('#', r'\\#')

                entry = f"""@article{{{citation_key},
  title     = {{{title}}},
  author    = {{{formatted_authors_esc}}},
  journal   = {{{journal_esc}}},
  year      = {{{year}}},
  volume    = {{{volume}}},
  number    = {{{issue}}},
  pages     = {{{pages}}},
  doi       = {{{doi}}},  # No escaping needed
  pmid      = {{{pmid}}},  # No escaping needed
  url       = {{{url}}}   # No escaping needed
}}"""
                entries.append(entry)
            except Exception as e:
                print(f"Warning: Could not generate BibTeX entry for study {i}: {str(e)}")
                continue

        return "\n\n".join(entries)


class LaTeXArticleGenerator:
    """Generates systematic review article in LaTeX format using LLM API.

    This class orchestrates the complete process of generating a publication-ready
    LaTeX systematic review article by leveraging Large Language Model APIs. It
    constructs comprehensive prompts, handles API communication with retry logic,
    processes streaming responses, and manages the complete document generation.

    The class supports multiple LLM providers (Anthropic, OpenRouter, Together,
    Groq, local) with appropriate authentication and request formatting for each.
    It includes robust error handling, rate limiting, and streaming capabilities
    for generating large documents efficiently.

    Attributes:
        data (dict): Dictionary containing all collected review data from
                    ArticleDataCollector, including screening results,
                    extracted studies, quality assessments, synthesis,
                    and computed statistics
        provider (str): LLM provider name ('anthropic', 'openrouter', 'together',
                       'groq', 'local') - determines API endpoint and authentication
        base_url (str): Base URL for the LLM API provider
        endpoint (str): API endpoint path for chat completions
        full_url (str): Complete API URL for making requests
        model (str): LLM model name to use for generation
        api_key (str): API authentication key (None for local provider)
        api_configs (dict): Configuration dictionary with provider-specific
                           settings including base URLs, endpoints, and
                           default model names
    """

    def __init__(self, data: Dict, provider: str = 'anthropic',
                 model: Optional[str] = None, api_url: Optional[str] = None,
                 api_key: Optional[str] = None, verbose: bool = False, **kwargs):
        """Initialize generator with config and collected data.

        This constructor sets up the LaTeX article generator with all necessary
        configuration for communicating with the specified LLM provider and
        accessing the collected review data.

        The method configures API settings based on the provider, including
        authentication, endpoint URLs, and default models. It validates that
        required API keys are available for cloud providers and sets up
        appropriate fallbacks for local deployments.

        Args:
            data (dict): Comprehensive dictionary containing all collected review
                        data from ArticleDataCollector, including screening
                        results, extracted studies, quality assessments,
                        thematic synthesis, and computed statistics
            provider (str, optional): LLM provider name. Defaults to 'anthropic'.
                Supported providers:
                - 'anthropic': Anthropic Claude models
                - 'openrouter': OpenRouter API with various models
                - 'together': Together AI API
                - 'groq': Groq API with fast inference
                - 'local': Local Ollama deployment
            model (str, optional): Specific model name to use. If not specified,
                uses the provider's default model from api_configs
            api_url (str, optional): Custom API URL to override the provider's
                default base URL. Useful for testing or private deployments
            api_key (str, optional): API authentication key. If not specified,
                attempts to load from environment variables based on provider.
                Required for all providers except 'local'

        Raises:
            ValueError: If provider is not recognized in api_configs, or if
                       required API key is not found in environment variables
                       for cloud providers (except local)

        Note:
            For local provider, no API key is required. The constructor will
            succeed even if api_key is None or environment variables are missing.
        """
        self.data = data
        self.provider = provider.lower()
        self.verbose = verbose
        self.debug = kwargs.get('debug', False)

        # API configuration (same as in main pipeline)
        self.api_configs = {
            'anthropic': {
                'base_url': 'https://api.anthropic.com/v1',
                'endpoint': '/messages',
                'api_key_env': 'ANTHROPIC_API_KEY',
                'default_model': 'claude-opus-4-5-20251101',
            },
            'openrouter': {
                'base_url': 'https://openrouter.ai/api/v1',
                'endpoint': '/chat/completions',
                'api_key_env': 'OPENROUTER_API_KEY',
                'default_model': 'meta-llama/llama-2-70b-chat-hf',
            },
            'together': {
                'base_url': 'https://api.together.xyz/v1',
                'endpoint': '/chat/completions',
                'api_key_env': 'TOGETHER_API_KEY',
                'default_model': 'meta-llama/Llama-2-70b-chat-hf',
            },
            'groq': {
                'base_url': 'https://api.groq.com/openai/v1',
                'endpoint': '/chat/completions',
                'api_key_env': 'GROQ_API_KEY',
                'default_model': 'mixtral-8x7b-32768',
            },
            'local': {
                'base_url': 'http://localhost:11434/v1',
                'endpoint': '/chat/completions',
                'api_key_env': None,
                'default_model': 'llama2',
            }
        }

        if self.provider not in self.api_configs:
            raise ValueError(f"Unknown provider: {provider}")

        config = self.api_configs[self.provider]

        self.base_url = api_url or config['base_url']
        self.endpoint = config['endpoint']
        self.full_url = self.base_url.rstrip('/') + self.endpoint
        self.model = model or config['default_model']

        # Get API key
        if config['api_key_env']:
            self.api_key = api_key or os.getenv(config['api_key_env'])
            if not self.api_key and provider != 'local':
                raise ValueError(f"API key not found. Set {config['api_key_env']} environment variable")
        else:
            self.api_key = None

        print(f"✓ Initialized {provider.upper()} API client")
        print(f"  Model: {self.model}")

    def call_llm(self, prompt: str, max_retries: int = 3, stream: bool = False, temperature: float = 0.8, output_file: Optional[Path] = None, verbose: bool = False) -> str:
        """Execute LLM API call with comprehensive retry logic.

        This method handles the complete API communication flow with the LLM
        provider, including request formatting, response processing, error
        handling, and retry logic. It supports both streaming and non-streaming
        modes, with optional file output for streaming responses.

        The method implements exponential backoff for rate limiting and server
        errors, with different wait times for different error types. It
        properly formats requests for both Anthropic and OpenAI-compatible
        APIs, handling authentication and response parsing appropriately.

        Args:
            prompt (str): Complete prompt string containing all instructions
                         and data for generating the LaTeX article. This should
                         be a comprehensive prompt with structured requirements
            max_retries (int, optional): Maximum number of retry attempts for
                failed API calls. Defaults to 3. The method implements
                exponential backoff between retries
            stream (bool, optional): Whether to enable streaming response mode.
                Defaults to False. When True, processes response chunks as they
                arrive and optionally writes to file
            temperature (float, optional): Temperature parameter for LLM
                generation controlling randomness. Defaults to 0.8. Range is
                typically 0.0-2.0, where 0.0 is deterministic and higher
                values increase creativity
            output_file (Path, optional): File path to write streaming output
                to. If provided and streaming is enabled, chunks are written
                to this file as they're received. File is created with parent
                directories if needed
            verbose (bool, optional): Whether to print streaming response content
                to console. Defaults to False. When True and streaming is enabled,
                prints each chunk as it's received

        Returns:
            str: Generated text content from LLM. In streaming mode with
                output_file specified, returns empty string as content is
                written directly to file. In non-streaming mode, returns
                complete generated content

        Raises:
            ValueError: If API call fails after all retry attempts exhausted.
                This can happen due to:
                - Authentication failures (invalid API key)
                - Rate limiting (after all retries)
                - Server errors (after all retries)
                - Network connectivity issues (after all retries)
                - Invalid API responses

        Note:
            The method handles different error types with appropriate retry
            strategies:
            - Rate limiting (429): Waits 5s, 10s, 15s for successive retries
            - Server errors (5xx): Waits 2s, 4s, 6s for successive retries
            - Network errors: Waits 2s, 4s, 6s for successive retries
            - Other errors: Waits 2s between retries
        """

        # Prepare request based on provider
        if self.provider == 'anthropic':
            headers = {
                'Content-Type': 'application/json',
                'x-api-key': self.api_key,
                'anthropic-version': '2023-06-01'
            }
            body = {
                'model': self.model,
                'max_tokens': 20000,  # Increased for longer articles
                'temperature': temperature,
                'messages': [{'role': 'user', 'content': prompt}]
            }
            if stream:
                body['stream'] = True
                headers['Accept'] = 'text/event-stream'
        else:  # OpenAI-compatible
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {self.api_key}' if self.api_key else ''
            }
            body = {
                'model': self.model,
                'max_tokens': 20000,  # Increased for longer articles
                'temperature': temperature,
                'messages': [{'role': 'user', 'content': prompt}]
            }
            if stream:
                body['stream'] = True

        # Convert body to JSON bytes
        body_json = json.dumps(body).encode('utf-8')

        # Retry loop
        for attempt in range(max_retries):
            try:
                req = urllib.request.Request(
                    self.full_url,
                    data=body_json,
                    headers=headers,
                    method='POST'
                )

                if stream:
                    # Handle streaming response
                    response = urllib.request.urlopen(req, timeout=60)
                    full_response = ""

                    # Open output file if provided
                    file_handle = None
                    if output_file:
                        output_file.parent.mkdir(parents=True, exist_ok=True)
                        file_handle = open(output_file, 'w', encoding='utf-8')

                    try:
                        for line in response:
                            data_str = line.decode('utf-8').strip()
                            if data_str.startswith('data: '):
                                data_str = data_str[6:]
                                try:
                                    chunk_data = json.loads(data_str)
                                    if "choices" in chunk_data and len(chunk_data["choices"]) > 0:
                                        delta = chunk_data["choices"][0].get("delta", {})
                                        if "content" in delta:
                                            content = delta["content"]
                                            full_response += content

                                            # Write to file and optionally print
                                            if file_handle:
                                                file_handle.write(content)
                                                # Only flush if content contains a newline
                                                if '\n' in content:
                                                    file_handle.flush()
                                            if self.verbose:
                                                print(content, end="", flush=True)
                                except json.JSONDecodeError:
                                    # Skip invalid JSON lines
                                    pass
                    finally:
                        if file_handle:
                            file_handle.close()

                    return full_response
                else:
                    # Handle non-streaming response
                    with urllib.request.urlopen(req, timeout=60) as response:
                        response_data = json.loads(response.read().decode('utf-8'))

                        # Extract response based on provider
                        if self.provider == 'anthropic':
                            result = response_data.get('content', [{}])[0].get('text', '')
                        else:
                            result = response_data.get('choices', [{}])[0].get('message', {}).get('content', '')

                        if not result:
                            raise ValueError("Empty response from API")

                        return result

            except urllib.error.HTTPError as e:
                if e.code == 429:  # Rate limit
                    wait_time = 5 * (attempt + 1)
                    print(f"  Rate limited. Waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                elif e.code in [500, 502, 503, 504]:  # Server error
                    wait_time = 2 * (attempt + 1)
                    print(f"  Server error ({e.code}). Waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise ValueError(f"API error {e.code}")

            except urllib.error.URLError as e:
                if attempt < max_retries - 1:
                    wait_time = 2 * (attempt + 1)
                    print(f"  Connection error. Waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                raise ValueError(f"Connection error: {e.reason}")

            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"  Error: {str(e)}. Retrying...")
                    time.sleep(2)
                    continue
                raise

        raise ValueError("Failed to get response after all retries")

    def generate_article(self, stream: bool = False, temperature: float = 0.8) -> str:
        """Generate complete LaTeX article from collected data.

        This method orchestrates the complete article generation process by
        first building a comprehensive prompt with all review data and
        formatting instructions, then making the LLM API call to generate
        the complete LaTeX document.

        The method handles both streaming and non-streaming modes, with
        appropriate file handling for streaming output. It includes debug
        features like saving the prompt to disk for troubleshooting and
        provides clear status messages during the generation process.

        Args:
            stream (bool, optional): Whether to enable streaming response
                mode. Defaults to False. When True, content is written directly
                to '06_review.tex' as it's received. When False, complete
                content is returned as a string
            temperature (float, optional): Temperature parameter for LLM
                generation controlling randomness. Defaults to 0.8. Higher
                values increase creativity but may reduce consistency

        Returns:
            str: Complete LaTeX document source as string. In streaming mode,
                returns empty string as content is written directly to file.
                In non-streaming mode, returns the complete generated LaTeX
                document ready for writing to file

        Note:
            This method makes a single comprehensive LLM API call with a
            detailed prompt that includes:
            - Complete review data and statistics
            - Structured article requirements (abstract, introduction, methods, etc.)
            - LaTeX formatting instructions
            - Content quality guidelines
            - Specific data to include

            For streaming mode, the output file '06_review.tex' is created
            in the working directory and written incrementally. For debugging,
            the complete prompt is saved to 'debug/' directory with
            timestamp.

            The generation process may take several minutes for large articles
            or when using models with context limits.
        """

        print("\nGenerating LaTeX article...")

        # Build comprehensive prompt with all data
        prompt = self._build_article_prompt()

        print(f"Prompt size for LLM call: {len(prompt) / 1024:.1f} KB")

        # Save prompt to filesystem for debugging
        if self.debug:
            debug_dir = Path(self.data['workdir']) / 'debug'
            debug_dir.mkdir(exist_ok=True)
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            prompt_file = debug_dir / f'prompt_{timestamp}.txt'
            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(prompt)
            print(f"  Prompt saved to: {prompt_file}")

        if stream:
            print("Streaming response from LLM...")
            # Create output file path for streaming
            output_file = Path(self.data['workdir']) / '06_review.tex'
            # Call LLM API to generate article content with streaming to file
            article_content = self.call_llm(prompt, stream=stream, temperature=temperature, output_file=output_file)
            # Response is empty when streaming to file
            return ""
        else:
            print("Making LLM call (this may take several minutes)...")
            # Call LLM API to generate article content
            article_content = self.call_llm(prompt, stream=stream, temperature=temperature)
            # Response is expected to be the complete LaTeX document source
            return article_content

    def _build_article_prompt(self) -> str:
        """Construct the complete LLM prompt with structured content requirements.

        This method creates a comprehensive prompt that provides the LLM with
        all necessary information to generate a publication-ready systematic
        review article. The prompt includes detailed instructions for structure,
        content, formatting, and quality requirements.

        The prompt is structured to guide the LLM through generating each
        section of the article with specific requirements for content,
        length, and academic rigor. It includes all collected data formatted
        appropriately and specific guidance for LaTeX formatting.

        Returns:
            str: Comprehensive prompt string containing:
                - Role definition and task instructions
                - Data summary overview
                - Complete extracted articles data
                - Quality assessment results
                - Characteristics table data
                - Thematic synthesis content
                - Detailed article structure requirements
                - Section-specific content guidelines
                - LaTeX formatting instructions
                - Quality and style guidelines

        Note:
            The prompt is designed to be comprehensive and provide clear
            guidance for generating a high-quality academic article. It
            includes specific word count targets, structural requirements,
            and formatting instructions to ensure consistency.

            The prompt size can be substantial (often 100KB+), so it's
            saved to disk for debugging purposes when generating articles.
        """
        try:
            # Get review metadata
            plan = self.data.get('plan', {})
            title = plan.get('title', 'Systematic Review')
            topic = plan.get('topic', 'the research topic')
            analysis_points = plan.get('analysis', [])
            
            # Generate data summary using the existing function
            data_summary = self._format_data_for_prompt()
            
            # Format data sections
            extracted_data = json.dumps(self.data.get('extracted', {}), indent=2)
            quality_data = json.dumps(self.data.get('quality', {}), indent=2)
            characteristics_data = json.dumps(self.data.get('characteristics_table', {}), indent=2)
            synthesis_data = self.data.get('synthesis', '')
            quality_summary = self._format_quality_data()
            
            # Format analysis points
            analysis_points_str = '\n'.join(f'      * {point}' for point in analysis_points)
            
            # Format extract fields
            extract_fields = plan.get('extract', {})
            extract_fields_str = '\n'.join(f'      * {field.replace("_", " ")}: {desc}' for field, desc in extract_fields.items())
            
            # Use template with placeholders
            prompt_template = self._get_prompt_template()
            
            # Format the prompt with data
            prompt = prompt_template.format(
                title=title,
                topic=topic,
                data_summary=data_summary,
                extracted_data=extracted_data,
                quality_data=quality_data,
                characteristics_data=characteristics_data,
                synthesis_data=synthesis_data,
                analysis_points=analysis_points_str,
                quality_summary=quality_summary,
                extract_fields=extract_fields_str
            )
            
            return prompt
            
        except (FileNotFoundError, IOError) as e:
            print(f"Error loading prompt template: {str(e)}")
            # Fallback to a simple prompt
            return f"Generate a LaTeX article about {topic} with the following data:\n{self._format_data_for_prompt()}"
    
    def _get_prompt_template(self) -> str:
        """Load the prompt template from file.
        
        Returns:
            str: Template string with placeholders for dynamic content
            
        Raises:
            FileNotFoundError: If the prompt template file cannot be found
            IOError: If the prompt template file cannot be read
        """
        # Get the directory containing this script
        script_dir = Path(__file__).parent
        prompt_file = script_dir / 'prompts' / 'latex_article_template.txt'
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            raise FileNotFoundError(f"Prompt template file not found: {prompt_file}")
        except IOError as e:
            raise IOError(f"Error reading prompt template file {prompt_file}: {str(e)}")

    def _format_data_for_prompt(self) -> str:
        """Create human-readable summary of collected data for inclusion in prompt.

        This method formats the collected review data into a human-readable
        summary organized by category. It presents key statistics and data
        points in a clear, structured format that's easy for the LLM to
        process and reference during article generation.

        The summary includes screening results, study statistics, quality
        assessment data, and other key metrics organized with clear
        section headers and consistent formatting.

        Returns:
            str: Formatted string containing organized data summary with
                sections for:
                - Screening results with PRISMA flow numbers
                - Study statistics including modalities, domains, designs
                - Sample size statistics
                - Performance metrics
                - Quality assessment summary
                - Thematic synthesis excerpt

        Note:
            This method is designed to provide the LLM with a clear overview
            of the collected data without overwhelming it with raw JSON data.
            The summary highlights key patterns and statistics that are most
            relevant for article generation.
        """
        lines = []

        # Screening data
        screening = self.data.get('screening', {})
        lines.append("SCREENING RESULTS:")
        lines.append(f"  - Total articles identified: {screening.get('total_identified', 0)}")
        lines.append(f"  - Articles screened: {screening.get('total_screened', 0)}")
        lines.append(f"  - Articles excluded (screening): {screening.get('excluded', 0)}")
        lines.append(f"  - Articles marked uncertain: {screening.get('uncertain', 0)}")
        lines.append(f"  - Full-text assessed: {screening.get('full_text_assessed', 0)}")
        lines.append(f"  - Full-text excluded: {screening.get('full_text_excluded', 0)}")
        lines.append(f"  - Final studies included: {screening.get('final_included', 0)}")
        lines.append("")

        # Statistics
        stats = self.data.get('statistics', {})
        lines.append("STUDY STATISTICS:")
        lines.append(f"  - Total studies: {stats.get('total_studies', 0)}")
        lines.append(f"  - Year range: {stats.get('year_range', 'N/A')}")

        lines.append("  Modalities studied:")
        for mod, count in stats.get('modalities', {}).items():
            lines.append(f"    - {mod}: {count}")

        lines.append("  Clinical domains:")
        for domain, count in stats.get('domains', {}).items():
            lines.append(f"    - {domain}: {count}")

        # Display extract fields statistics
        extract_fields = stats.get('extract_fields', {})
        if extract_fields:
            lines.append("  Extract Fields:")
            for field_name, field_stats in extract_fields.items():
                lines.append(f"    {field_name}:")
                for value, count in field_stats.items():
                    lines.append(f"      - {value}: {count}")

        lines.append("  Study designs:")
        for design, count in stats.get('study_designs', {}).items():
            lines.append(f"    - {design}: {count}")

        # Sample sizes
        sample_stats = stats.get('sample_sizes', {})
        lines.append("  Sample sizes:")
        lines.append(f"    - Median: {sample_stats.get('median', 'N/A')}")
        lines.append(f"    - Range: {sample_stats.get('range', 'N/A')}")

        # Performance metrics
        perf = stats.get('performance_metrics', {})
        lines.append("  Performance metrics:")
        if perf.get('sensitivity'):
            lines.append(f"    - Sensitivity: {perf['sensitivity']}")
        if perf.get('specificity'):
            lines.append(f"    - Specificity: {perf['specificity']}")
        if perf.get('auc'):
            lines.append(f"    - AUC: {perf['auc']}")

        lines.append("")

        # Quality assessment
        lines.append("QUALITY ASSESSMENT SUMMARY:")
        quality = self.data.get('quality', [])
        if quality:
            low_risk = sum(1 for q in quality if q.get('overall_bias') == 'Low')
            mod_risk = sum(1 for q in quality if q.get('overall_bias') == 'Moderate')
            high_risk = sum(1 for q in quality if q.get('overall_bias') == 'High')
            lines.append(f"  - Low risk: {low_risk} ({100*low_risk//len(quality)}%)")
            lines.append(f"  - Moderate risk: {mod_risk} ({100*mod_risk//len(quality)}%)")
            lines.append(f"  - High risk: {high_risk} ({100*high_risk//len(quality)}%)")
        lines.append("")

        # Thematic synthesis
        synthesis = self.data.get('synthesis', '')
        if synthesis:
            lines.append("THEMATIC SYNTHESIS (extended excerpt):")
            # Include first 6000 characters of synthesis
            lines.append(synthesis[:6000])
            if len(synthesis) > 6000:
                lines.append("... [additional synthesis content available]")
            lines.append("")

        return "\n".join(lines)

    def _format_quality_data(self) -> str:
        """Create summary of quality assessment for inclusion in prompt.

        This method processes the quality assessment data to create a concise
        summary suitable for inclusion in the LLM prompt. It calculates the
        distribution of studies across different risk of bias categories.

        The summary provides the LLM with context about the methodological
        quality of the included studies, which is important for discussing
        the strengths and limitations of the evidence in the article.

        Returns:
            str: JSON string containing quality assessment summary with:
                - total_assessed: Total number of studies assessed
                - low_risk: Number of studies with low risk of bias
                - moderate_risk: Number of studies with moderate risk of bias
                - high_risk: Number of studies with high risk of bias

        Note:
            If no quality assessment data is available, returns "No quality data"
            string instead of JSON. This allows the prompt to handle missing
            data gracefully.
        """
        quality = self.data.get('quality', [])
        if not quality:
            return "No quality data"

        summary = {
            'total_assessed': len(quality),
            'low_risk': sum(1 for q in quality if q.get('overall_bias') == 'Low'),
            'moderate_risk': sum(1 for q in quality if q.get('overall_bias') == 'Moderate'),
            'high_risk': sum(1 for q in quality if q.get('overall_bias') == 'High'),
        }

        return json.dumps(summary, indent=2)


def generate_article_main(workdir: str, provider: str = 'openrouter',
                         model: Optional[str] = None, api_url: Optional[str] = None,
                         api_key: Optional[str] = None, stream: bool = False,
                         temperature: float = 0.8, verbose: bool = False, debug: bool = False) -> Path:
    """Main entry point for article generation.

    This function orchestrates the complete LaTeX article generation process,
    from data collection through final file output. It serves as the primary
    interface for generating systematic review articles from pipeline outputs.

    The function coordinates between the ArticleDataCollector for gathering
    and organizing data, and the LaTeXArticleGenerator for creating the
    actual document. It handles both streaming and non-streaming modes,
    with appropriate file management and error handling.

    Args:
        workdir (str): Path to directory containing pipeline output files.
            This directory should contain all generated files from the
            systematic review pipeline, including:
            - 00_plan.json: Study protocol information
            - 01_parsed_articles.json: Original parsed articles
            - 02_screening_results.json: Screening statistics
            - 03_extracted_data.json: Extracted study data
            - 04_quality_assessment.json: Quality assessment results
            - 05_thematic_synthesis.txt: Thematic synthesis text
            - summary_characteristics_table.csv: Study characteristics
        provider (str, optional): LLM provider name. Defaults to 'openrouter'.
            Supported providers: 'anthropic', 'openrouter', 'together',
            'groq', 'local'. Determines API endpoint and authentication
        model (str, optional): Specific model name to use. If not specified,
            uses the provider's default model
        api_url (str, optional): Custom API URL to override provider's default
        api_key (str, optional): API authentication key. If not specified,
            attempts to load from environment variables
        stream (bool, optional): Whether to enable streaming response mode.
            Defaults to False. When True, writes content incrementally to file
        temperature (float, optional): LLM temperature parameter controlling
            randomness. Defaults to 0.8. Range typically 0.0-2.0
        verbose (bool, optional): Whether to print streaming response content
            to console. Defaults to False

    Returns:
        Path: Path object pointing to the generated LaTeX file
            ('06_review.tex' in the workdir). Also generates 'references.bib'
            in the same directory

    Raises:
        ValueError: If data collection fails or API errors occur during
            article generation. This can happen due to:
            - Missing or invalid pipeline output files
            - API authentication failures
            - API rate limiting or server errors
            - Network connectivity issues
            - File I/O errors when saving outputs

    Note:
        The function handles both streaming and non-streaming modes differently:
        - Streaming mode: Content written incrementally to '06_review.tex'
          during API calls, with BibTeX references written separately
        - Non-streaming mode: Complete content generated then written to file

        After successful generation, prints compilation instructions for
        XeLaTeX and bibtex to create the final PDF document.
    """

    workdir = Path(workdir)

    # Collect data
    collector = ArticleDataCollector(str(workdir))
    data = collector.collect_all_data()

    # Generate article
    generator = LaTeXArticleGenerator(
        data,
        provider=provider,
        model=model,
        api_url=api_url,
        api_key=api_key,
        verbose=verbose,
        debug=debug
    )

    if stream:
        # For streaming, the file is written directly during the API call
        output_file = workdir / '06_review.tex'
        article_content = generator.generate_article(stream=stream, temperature=temperature)

        # Save BibTeX references
        bib_file = workdir / 'references.bib'
        bib_content = collector.generate_bibtex()
        with open(bib_file, 'w', encoding='utf-8') as f:
            f.write(bib_content)
    else:
        # For non-streaming, write the complete content at once
        article_content = generator.generate_article(stream=stream, temperature=temperature)
        output_file = workdir / '06_review.tex'
        bib_file = workdir / 'references.bib'

        try:
            # Save LaTeX article
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(article_content)

            # Save BibTeX references
            bib_content = collector.generate_bibtex()
            with open(bib_file, 'w', encoding='utf-8') as f:
                f.write(bib_content)
        except IOError as e:
            print(f"Error: Could not save output files: {str(e)}")
            raise

    print(f"\n✓ Article generated successfully!")
    print(f"  Saved to: {output_file}")
    print(f"  References saved to: {bib_file}")
    if not stream:
        print(f"  Total size: {len(article_content) + len(bib_content)} bytes")

    # Try to compile
    print("\nNote: To compile the XeLaTeX document with references:")
    print(f"  bibtex {output_file.stem}")
    print(f"  xelatex {output_file.name}")

    return output_file


# Command line interface
if __name__ == '__main__':
    """Command line interface for LaTeX article generator.

    This script provides a command-line interface for generating systematic
    review articles from pipeline outputs. It supports multiple LLM providers,
    streaming mode, and various configuration options.

    Usage examples:
        python generate_latex_article.py /path/to/workdir
        python generate_latex_article.py /path/to/workdir --provider anthropic
        python generate_latex_article.py /path/to/workdir --stream --verbose
        python generate_latex_article.py /path/to/workdir --model claude-3-opus-20240229

    The script handles argument parsing, validates inputs, and calls the
    main article generation function with appropriate parameters. It includes
    comprehensive error handling and user-friendly error messages.
    """
    parser = argparse.ArgumentParser(
        description='Generate LaTeX systematic review article from pipeline outputs',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s /path/to/workdir
  %(prog)s /path/to/workdir --provider anthropic
  %(prog)s /path/to/workdir --stream --verbose
  %(prog)s /path/to/workdir --model claude-3-opus-20240229 --temperature 0.7
        """
    )
    parser.add_argument('workdir', help='Directory with pipeline outputs')
    parser.add_argument('-p', '--provider', choices=['anthropic', 'openrouter', 'together', 'groq', 'local'],
                       default='openrouter', help='LLM provider')
    parser.add_argument('-m', '--model', help='Model name (uses provider default if not specified)')
    parser.add_argument('-u', '--api-url', help='Custom API URL')
    parser.add_argument('-k', '--api-key', help='API key (uses env var if not specified)')
    parser.add_argument('-s', '--stream', action='store_true', help='Enable streaming response')
    parser.add_argument('-t', '--temperature', type=float, default=0.8, help='LLM temperature (default: 0.8)')
    parser.add_argument('-v', '--verbose', action='store_true', help='Print response content in streaming mode')
    parser.add_argument('-d', '--debug', action='store_true', help='Enable debug mode')

    args = parser.parse_args()

    try:
        generate_article_main(
            args.workdir,
            provider=args.provider,
            model=args.model,
            api_url=args.api_url,
            api_key=args.api_key,
            stream=args.stream,
            temperature=args.temperature,
            verbose=args.verbose,
            debug=args.debug
        )
    except Exception as e:
        print(f"Error: {str(e)}")
        import traceback
        traceback.print_exc()
        exit(1)
